#!/usr/bin/env python3
"""
SHARED JOB SCRAPER - Gemensam jobbskrapning f√∂r alla modeller
S√§kerst√§ller konsistent jobbdata-extraktion oavsett vilken modell som anv√§nds
"""

import hashlib
from pathlib import Path
from typing import Tuple, Optional
from loguru import logger

from src.utils.chrome_utils import init_browser
from src.libs.resume_and_cover_builder.llm.llm_job_parser import LLMParser
from src.job import Job
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By

class SharedJobScraper:
    """
    Gemensam jobbskrapning som alla modeller anv√§nder.
    S√§kerst√§ller konsistent beteende och felhantering.
    """
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.driver = None
        self.job_parser = None
        
    def scrape_job_from_url(self, job_url: str) -> Tuple[Job, str]:
        """
        Skrapar jobb fr√•n URL och returnerar Job-objekt + suggested_name
        SAMMA LOGIK SOM URSPRUNGLIG ResumeFacade.link_to_job()
        
        Args:
            job_url: URL till jobbet
            
        Returns:
            Tuple[Job, str]: (Job-objekt, suggested_name f√∂r PDF)
        """
        logger.info(f"üåê Startar jobbskrapning fr√•n URL: {job_url}")
        
        try:
            # 1. Initiera WebDriver (SAMMA SOM URSPRUNGLIG)
            self.driver = init_browser()
            self.driver.get(job_url)
            self.driver.implicitly_wait(10)  # Samma timeout som ursprunglig
            
            # V√§nta p√• att sidan laddas med explicit wait
            try:
                wait = WebDriverWait(self.driver, 15)
                wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
                logger.debug("Sida laddad framg√•ngsrikt")
            except Exception as e:
                logger.warning(f"Timeout vid sidladdning, forts√§tter √§nd√•: {e}")
            
            # 2. Extrahera HTML-inneh√•ll
            body_element = self.driver.find_element("tag name", "body")
            body_html = body_element.get_attribute("outerHTML")
            
            logger.debug(f"HTML extraherat: {len(body_html)} tecken")
            
            # 3. Anv√§nd LLMParser f√∂r att extrahera jobbinformation (SAMMA SOM URSPRUNGLIG)
            self.job_parser = LLMParser(openai_api_key=self.api_key)
            self.job_parser.set_body_html(body_html)
            
            # 4. Skapa Job-objekt (EXAKT SAMMA LOGIK SOM ResumeFacade)
            job = Job()
            job.role = self.job_parser.extract_role()
            job.company = self.job_parser.extract_company_name()
            job.description = self.job_parser.extract_job_description()
            job.location = self.job_parser.extract_location()
            job.link = job_url
            
            # 5. Generera suggested_name (SAMMA SOM URSPRUNGLIG)
            suggested_name = hashlib.md5(job_url.encode()).hexdigest()[:10]
            
            logger.info(f"‚úÖ Jobb extraherat: {job.role} p√• {job.company} i {job.location}")
            logger.info(f"üìÑ Suggested name: {suggested_name}")
            
            return job, suggested_name
            
        except Exception as e:
            logger.error(f"‚ùå Fel vid jobbskrapning: {e}")
            raise
        finally:
            # St√§ng WebDriver
            if self.driver:
                self.driver.quit()
                self.driver = None
    
    def validate_job_data(self, job: Job) -> bool:
        """
        Validerar att jobbdata √§r komplett
        
        Args:
            job: Job-objekt att validera
            
        Returns:
            bool: True om data √§r giltig
        """
        required_fields = ['role', 'company', 'description']
        
        for field in required_fields:
            value = getattr(job, field, None)
            if not value or value.strip() == "":
                logger.warning(f"‚ö†Ô∏è Saknar eller tom data f√∂r: {field}")
                return False
        
        logger.info("‚úÖ Jobbdata validerad - alla obligatoriska f√§lt finns")
        return True
    
    def get_job_summary(self, job: Job) -> str:
        """
        Skapar en sammanfattning av jobbdata f√∂r logging
        
        Args:
            job: Job-objekt
            
        Returns:
            str: Formaterad sammanfattning
        """
        return f"""
üéØ JOBB-SAMMANFATTNING:
   ‚Ä¢ Roll: {job.role or 'N/A'}
   ‚Ä¢ F√∂retag: {job.company or 'N/A'}
   ‚Ä¢ Plats: {job.location or 'N/A'}
   ‚Ä¢ Beskrivning: {len(job.description)} tecken
   ‚Ä¢ URL: {job.link or 'N/A'}
"""

def create_shared_scraper(api_key: str) -> SharedJobScraper:
    """
    Factory-funktion f√∂r att skapa SharedJobScraper
    
    Args:
        api_key: OpenAI API-nyckel
        
    Returns:
        SharedJobScraper: Konfigurerad scraper-instans
    """
    return SharedJobScraper(api_key)

# Convenience-funktion f√∂r enkel anv√§ndning
def scrape_job_unified(api_key: str, job_url: str) -> Tuple[Job, str]:
    """
    Enkel funktion f√∂r att skrapa jobb - kan anv√§ndas av alla modeller
    
    Args:
        api_key: OpenAI API-nyckel
        job_url: URL till jobbet
        
    Returns:
        Tuple[Job, str]: (Job-objekt, suggested_name)
    """
    scraper = create_shared_scraper(api_key)
    job, suggested_name = scraper.scrape_job_from_url(job_url)
    
    # Validera data
    if not scraper.validate_job_data(job):
        logger.warning("‚ö†Ô∏è Jobbdata √§r ofullst√§ndig men forts√§tter √§nd√•")
    
    # Logga sammanfattning
    logger.info(scraper.get_job_summary(job))
    
    return job, suggested_name

if __name__ == "__main__":
    # Test av shared scraper
    print("üß™ TESTAR SHARED JOB SCRAPER")
    print("=" * 50)
    print("‚ö†Ô∏è Detta √§r en test-version. Anv√§nd med riktig API-nyckel f√∂r produktion.")
    
    # Exempel p√• anv√§ndning
    print("\nüìã EXEMPEL P√Ö ANV√ÑNDNING:")
    print("from src.libs.resume_and_cover_builder.shared_job_scraper import scrape_job_unified")
    print("job, suggested_name = scrape_job_unified(api_key, job_url)")
    print("print(f'Jobb: {job.role} p√• {job.company}')")
